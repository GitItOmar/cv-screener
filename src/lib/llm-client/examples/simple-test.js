#!/usr/bin/env node
/**
 * Simple test for the simplified LLM Client (no rate limiting or retries)
 */

import { LLMClient, PromptBuilder } from '../src/index.js';

async function main() {
  console.log('ğŸ¤– Simple LLM Client Test (No Rate Limiting/Retries)\n');

  try {
    // Test PromptBuilder
    console.log('ğŸ”§ Testing PromptBuilder...');
    const prompt = new PromptBuilder()
      .setRole('assistant')
      .addSystemMessage('You are a helpful assistant.')
      .addUserMessage('Please analyze this data: {{inputData}}')
      .withVariables({
        inputData: {
          title: 'Sample Document',
          content: 'This is a sample text for analysis.',
        },
      })
      .build();

    console.log('ğŸ“‹ Built prompt with', prompt.messages.length, 'messages');
    console.log('ğŸ¯ Role:', prompt.role);
    console.log('ğŸ“ Variables:', Object.keys(prompt.variables));
    console.log('âœ¨ Response Format:', prompt.responseFormat);

    // Test client creation (without actual API calls)
    console.log('\nğŸ“¦ Testing Client Creation...');
    const client = new LLMClient({
      provider: 'openai',
      model: 'gpt-4o',
      apiKey: 'test-key',
      costTracking: true,
      logging: false,
    });

    console.log('âœ… Client created successfully');
    console.log('âš™ï¸  Config:', {
      provider: client.config.provider,
      model: client.config.model,
      timeout: client.config.timeout,
      costTracking: client.config.costTracking,
    });

    console.log('\nâœ¨ All tests passed! No rate limiting or retry logic present.');
  } catch (error) {
    console.error('âŒ Error:', error.message);
  }
}

main().catch(console.error);
